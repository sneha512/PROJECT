# -*- coding: utf-8 -*-
"""CREDIT CARD FRAUD DETECTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pm9T0PxGp7UI-97hswMoVxSYNzP50J_S
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

# loading the dataset to a Pandas dataframe
credit_card_data = pd.read_csv('/content/creditcard.csv')

#first 5 rows of the dataset
credit_card_data.head()

credit_card_data.tail()

#dataset information
credit_card_data.info()

#checking the member of missing values in each column
credit_card_data.isnull().sum()

credit_card_data.shape

#drop missing values
credit_card_data=credit_card_data.dropna(how='any')

credit_card_data.isnull().sum()

# distribution of legit transactions and fraudulent transcations
# name['row'].value_count()
credit_card_data['Class'].value_counts()

#this dataset is highly unbalance
#0 --> Normal Transacction
#1 --> Fraud
# seperate the fraud and normal data for analysis
legit = credit_card_data[credit_card_data.Class==0]
fraud = credit_card_data[credit_card_data.Class==1]

print(legit.shape)
print(fraud.shape)

#statistiical measures of the data
legit.Amount.describe()

fraud.Amount.describe()

#compare the  values for both trans
credit_card_data.groupby('Class').mean()

#under-sampling for unbalanced data
#build a sample containing similar distribution of normal and fraud trans
#no .of fraud trans: 492
legit_sample = legit.sample(n=361)

#concantenating two dataframes
new_dataset = pd.concat([legit_sample,fraud],axis=0)

new_dataset.head()

new_dataset.tail()

new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

#spliting data int feactures and targets
x = new_dataset.drop(columns='Class',axis=1)
y = new_dataset['Class']

print(x)

print(y)

#spliting the data into training data and testing data
x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.2,stratify=y, random_state=2)

print(x.shape,x_train.shape,x_test.shape)

#Model training
#Logistic Regression for Binary
model =LogisticRegression()

#training the logistic Regression model with training data
model.fit(x_train,y_train)

#Model Evaluation
#Accuracy Score
#accuracy on training data
x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(x_train_prediction,y_train)

print('Accuracy on training data : ',training_data_accuracy)

corrleation = credit_card_data.corr()

plt.figure(figsize=(12,9))
sns.heatmap(corrleation,cbar=True,square=True,fmt='.1f',annot=True,annot_kws={'size':8},cmap='Blues')

#Model Evaluation
#Accuracy Score
#accuracy on test data
x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(x_test_prediction,y_test)

print('Accuracy on training data : ',test_data_accuracy)
